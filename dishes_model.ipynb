{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Classifying Images with a DNN Model\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we build a neural network to classify a dishes image dataset using a Deep Neural Network Model.\n",
    "The images of the dishes dataset are labeled as American, Chinese, European, Indian, Japanese or Korean.\n",
    "\n",
    "## Installing dependencies\n",
    "The minimum Python version used is 3.9, Keras and other dependencies can be installed with pip."
   ],
   "id": "e4ce5bc46d8d98a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install -r requirements.txt",
   "id": "f1f56d791889906b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Imports\n",
    "The following imports are required."
   ],
   "id": "cabf875273504e80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from os import path\n",
    "\n",
    "from keras import utils, Input, Model\n",
    "from keras.src.applications.efficientnet import EfficientNetB0\n",
    "from keras.src.layers import GlobalAveragePooling2D, BatchNormalization, Dropout, Dense\n",
    "from matplotlib import pyplot as plt"
   ],
   "id": "9b852759a15e1794",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Definitions\n",
    "First we define some variables for importing images and building the model."
   ],
   "id": "61989aa99328268c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Some definitions\n",
    "NUM_CLASSES = 6\n",
    "IMAGE_SIZE = 224\n",
    "IMAGE_CHANNELS = 3\n",
    "BATCH_SIZE = 64\n",
    "RANDOM_SEED = 58239\n",
    "\n",
    "# Define input shape\n",
    "INPUT_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)"
   ],
   "id": "ce05b1579a3f749d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Visualizing images\n",
    "We visualize some image samples to get an impression of the dataset."
   ],
   "id": "dca2203e32bbf100"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Show image samples\n",
    "filenames = [\"dataset/Dishes/American/American_309.jpg\", \"dataset/Dishes/Chinese/Chinese_751.jpg\",\n",
    "             \"dataset/Dishes/European/European_101.jpg\", \"dataset/Dishes/Indian/Indian_823.jpg\",\n",
    "             \"dataset/Dishes/Japanese/Japanese_111.jpg\", \"dataset/Dishes/Korean/Korean_100.jpg\"]\n",
    "for i, filename in enumerate(filenames):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.imshow(plt.imread(filename, format=None))\n",
    "    plt.title(f\"{path.basename(filename)}\")\n",
    "    plt.axis(\"off\") "
   ],
   "id": "ddddb069d4ff5788",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Create training and validation dataset\n",
    "Keras has nice mechanism to import images directly as datasets and label data by using the filenames of the folders. We can also split into training and validation dataset. Important is using same value for *seed* to avoid overlapping data between training and validation dataset."
   ],
   "id": "3a7eaa77864dea01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Creating training dataset directly from directory\n",
    "train_ds = utils.image_dataset_from_directory(\n",
    "    directory=\"dataset/dishes/\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    subset=\"training\",\n",
    "    seed=RANDOM_SEED,\n",
    "    validation_split=0.1)\n",
    "\n",
    "# Creating evaluation dataset directly from directory\n",
    "validation_ds = utils.image_dataset_from_directory(\n",
    "    directory=\"dataset/dishes/\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    subset=\"validation\",\n",
    "    seed=RANDOM_SEED,\n",
    "    validation_split=0.1)"
   ],
   "id": "1474ec8fb919f5c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Create model\n",
    "Now we apply transfer learning by using existing *EfficientNetB0* model and rebuild top layers."
   ],
   "id": "7e4b54c4d1262975"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create input layer\n",
    "inputs = Input(shape=INPUT_SHAPE)\n",
    "\n",
    "# Use EfficientNetB0 as basic model\n",
    "basic_model = EfficientNetB0(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
    "\n",
    "# Freeze the pretrained weights\n",
    "basic_model.trainable = False\n",
    "\n",
    "# Rebuild top layers\n",
    "outputs = GlobalAveragePooling2D(name=\"avg_pool\")(basic_model.output)\n",
    "outputs = BatchNormalization()(outputs)\n",
    "outputs = Dropout(0.2, name=\"top_dropout\")(outputs)\n",
    "outputs = Dense(NUM_CLASSES, activation=\"softmax\", name=\"pred\")(outputs)\n",
    "\n",
    "# Merge to new model\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ],
   "id": "9d4e6471a1211f4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then we compile the model and start the training.",
   "id": "d417bd5f138b326e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compile and run training\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_ds, epochs=10, validation_data=validation_ds)"
   ],
   "id": "81bf155584042ba5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analyze performance\n",
    "After training is finished, we plot the accuracy metric for analysis purposes that we can optimize parameters and rerun training if needed."
   ],
   "id": "ec92d9b9b7f2414c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot accuracy metric\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"validation\"], loc=\"upper left\")"
   ],
   "id": "3595eafb03d818f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Save model\n",
    "Finally, when we are satisfied with the DNN performance, the model can be saved and then later be used for predictions."
   ],
   "id": "bd262d02a58d1a88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the model\n",
    "model.save(\"dishes_model.keras\")"
   ],
   "id": "b9c8c8b43920e073",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Congratulations, we are done! The file *dishes_model.py* includes all Python code covered here.",
   "id": "63ec0f526c7227c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
