{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dac3c7c",
   "metadata": {},
   "source": [
    "# Classifying Images with a DNN Model\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we demonstrate how to build an image classification model using a Deep Neural Network (DNN). The model is trained to recognize different types of dishes from images, classified into six categories: *American*, *Chinese*, *European*, *Indian*, *Japanese*, and *Korean*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1a485e",
   "metadata": {},
   "source": [
    "## Installing Dependencies\n",
    "Ensure you are using Python 3.9 or higher. To install all required packages, use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc01f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a68a5c",
   "metadata": {},
   "source": [
    "## Required Libraries\n",
    "We begin by importing all necessary libraries for image loading, model building, training, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07c7692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import tensorflow as tf\n",
    "from keras import utils, Input, Model\n",
    "from keras.applications.efficientnet import EfficientNetB0\n",
    "from keras.layers import GlobalAveragePooling2D, BatchNormalization, Dropout, Dense\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde4c3f5",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "We define essential constants for image size, batch size, and the number of output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaab382",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 6\n",
    "IMAGE_SIZE = 224\n",
    "IMAGE_CHANNELS = 3\n",
    "BATCH_SIZE = 64\n",
    "RANDOM_SEED = 58239\n",
    "INPUT_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af69a68e",
   "metadata": {},
   "source": [
    "## Visualize Sample Images\n",
    "Let's take a quick look at a few sample images from each class to understand the dataset visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3d24a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\n",
    "    \"dataset/Dishes/American/American_309.jpg\", \"dataset/Dishes/Chinese/Chinese_751.jpg\",\n",
    "    \"dataset/Dishes/European/European_101.jpg\", \"dataset/Dishes/Indian/Indian_823.jpg\",\n",
    "    \"dataset/Dishes/Japanese/Japanese_111.jpg\", \"dataset/Dishes/Korean/Korean_100.jpg\"]\n",
    "for i, filename in enumerate(filenames):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.imshow(plt.imread(filename))\n",
    "    plt.title(f\"{path.basename(filename)}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4614b70e",
   "metadata": {},
   "source": [
    "## Load and Split Dataset\n",
    "We use Keras utilities to load images from directories. The folder names are used as labels, and the data is automatically split into training and validation sets using a fixed random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47636d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = utils.image_dataset_from_directory(\n",
    "    directory=\"dataset/dishes/\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    subset=\"training\",\n",
    "    seed=RANDOM_SEED,\n",
    "    validation_split=0.1)\n",
    "\n",
    "validation_ds = utils.image_dataset_from_directory(\n",
    "    directory=\"dataset/dishes/\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    subset=\"validation\",\n",
    "    seed=RANDOM_SEED,\n",
    "    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4484a985",
   "metadata": {},
   "source": [
    "## Normalize Image Data\n",
    "We normalize the image pixel values to the range [0, 1] to improve model performance and training stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09fdd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "validation_ds = validation_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321075ae",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "We employ transfer learning by using EfficientNetB0 as the base model. The top layers are customized for our classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb0697",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=INPUT_SHAPE)\n",
    "base_model = EfficientNetB0(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
    "base_model.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D(name=\"avg_pool\")(base_model.output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2, name=\"top_dropout\")(x)\n",
    "outputs = Dense(NUM_CLASSES, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b926ec90",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Next, we compile the model using categorical cross-entropy loss and the RMSprop optimizer. The model is then trained on the dataset for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca8cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_ds, epochs=10, validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64142d7a",
   "metadata": {},
   "source": [
    "## Evaluate Training Results\n",
    "We plot the training and validation accuracy over the epochs to assess the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fea4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556c9ea8",
   "metadata": {},
   "source": [
    "## Save the Trained Model\n",
    "After training, we save the model to a file for later use in inference or further training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a5d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"dishes_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1634f51b",
   "metadata": {},
   "source": [
    "ðŸŽ‰ Congratulations! You've successfully built, trained, evaluated, and saved an image classification model using a DNN and transfer learning."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
